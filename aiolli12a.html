<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<!--#include virtual="/css-scroll.txt"-->
  <title>Transfer Learning by Kernel Meta-Learning</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="generator"
 content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)">
  <meta name="originator"
 content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)">
<!-- uni-html4,html -->
  <meta name="src" content="aiolli12a.tex">
  <meta name="date" content="2012-05-27 11:11:00">
  <link rel="stylesheet" type="text/css" href="aiolli12a.css">
</head>
<body>
<!--l. 143-->
<div id="content">
<div class="maketitle">
<h2 class="titleHead">Transfer Learning by Kernel Meta-Learning</h2>
</div>
<span class="cmbxti-10x-x-109">F. Aiolli</span>; JMLR W&amp;CP
27:81–95, 2012.
<div class="abstract"><!--l. 155-->
<p class="indent"> </p>
<h3>Abstract</h3>
A crucial issue in machine learning is how to learn appropriate
representations for
data. Recently, much work has been devoted to <span
 class="cmti-10x-x-109">kernel learning</span>, that is, the problem of
ﬁnding a
good kernel matrix for a given task. This can be done in a
semi-supervised learning setting by
using a large set of unlabeled data and a (typically small) set of <span
 class="cmmi-10x-x-109">i.i.d. </span>labeled data. Another, even
more challenging problem, is how one can exploit partially labeled data
of a source task to learn
good representations for a diﬀerent, but related, target task. This is
the main subject of <span class="cmti-10x-x-109">transfer</span>
<span class="cmti-10x-x-109">learning</span>.
<!--l. 166-->
<p class="indent"> In this paper, we present a novel approach to
transfer learning based on kernel learning.
Speciﬁcally, we propose a <span class="cmti-10x-x-109">kernel
meta-learning </span>algorithm which, starting from a basic kernel,
tries
to learn chains of kernel transforms that are able to produce good
kernel matrices for the
source tasks. The same sequence of transformations can be then applied
to compute
the kernel matrix for new related target tasks. We report on the
application of this
method to the ﬁve datasets of the Unsupervised and Transfer Learning
(UTL) challenge
benchmark<span class="footnote-mark"><a href="aiolli12a2.html#fn1x0"><sup
 class="textsuperscript">1</sup></a></span> ,
where we won the ﬁrst phase of the competition. </p>
</div>
<hr><br>
<br>
</div>
<!--#include virtual="/nav-bar.txt"-->
</body>
</html>
