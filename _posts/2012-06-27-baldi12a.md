---
pdf: http://jmlr.org/proceedings/papers/v27/baldi12a.pdf
section: theory
title: Autoencoders, Unsupervised Learning, and Deep Architectures
abstract: Autoencoders play a fundamental role in unsupervised learning and in deep
  architectures for transfer learning and other tasks. In spite of their fundamental
  role, only linear autoencoders over the real numbers have been solved analytically.
  Here we present a general mathematical framework for the study of both linear and
  non-linear autoencoders. The framework allows one to derive an analytical treatment
  for the most non-linear autoencoder, the Boolean autoencoder. Learning in the Boolean
  autoencoder is equivalent to a clustering problem that can be solved in polynomial
  time when the number of clusters is small and becomes NP complete when the number
  of clusters is large. The framework sheds light on the different kinds of autoencoders,
  their learning complexity, their horizontal and vertical composability in deep architectures,
  their critical points, and their fundamental connections to clustering, Hebbian
  learning, and information theory.
layout: inproceedings
id: baldi12a
month: 0
firstpage: 37
lastpage: 49
page: 37-49
sections: 
author:
- given: P.
  family: Baldi
reponame: v27
date: 2012-06-27
address: Bellevue, Washington, USA
publisher: PMLR
container-title: Proceedings of ICML Workshop on Unsupervised and Transfer Learning
volume: '27'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 6
  - 27
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
